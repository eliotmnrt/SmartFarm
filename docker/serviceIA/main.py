import joblib
import pandas as pd
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

# Chargement du cerveau au dÃ©marrage
model = joblib.load('field_state_model.pkl')
scaler = joblib.load('field_scaler.pkl')

# DÃ©finition des noms d'Ã©tats (basÃ© sur notre analyse ci-dessus)
STATE_LABELS = {
    0: "âš ï¸ Risque Carence (Azote bas)",
    1: "ğŸŸ¢ Croissance Optimale",
    2: "ğŸ”µ Repos / Nuit"
}

# ModÃ¨le de donnÃ©es attendu en entrÃ©e
class SensorData(BaseModel):
    temperature_ambiante_c: float
    temperature_sol_c: float       # <--- Nouveau
    humidite_ambiante: float     # <--- Nouveau
    humidite_sol: float
    azote_mg_kg: float
    phosphore_mg_kg: float         # <--- Nouveau
    potassium_mg_kg: float         # <--- Nouveau
    ph: float

@app.post("/predict_state")
def predict_state(data: SensorData):
    # 1. PrÃ©parer les donnÃ©es
    # Attention: l'ordre doit Ãªtre identique Ã  l'entraÃ®nement !
    features = [[
        data.temperature_ambiante_c,
        data.temperature_sol_c,
        data.humidite_ambiante,
        data.humidite_sol,
        data.azote_mg_kg,
        data.phosphore_mg_kg,
        data.potassium_mg_kg,
        data.ph
    ]]
    
    # 2. Normaliser
    features_scaled = scaler.transform(features)
    
    # 3. PrÃ©dire le cluster (0, 1 ou 2)
    cluster_id = int(model.predict(features_scaled)[0])
    
    # 4. Renvoyer l'interprÃ©tation
    return {
        "state_id": cluster_id,
        "description": STATE_LABELS.get(cluster_id, "Inconnu"),
        "confidence": "Automated estimation via K-Means"
    }

# Pour lancer : uvicorn ai_service:app --reload